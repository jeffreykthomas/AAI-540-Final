{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f1dd19-3ff7-4662-905b-5a70ed923f70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU pip transformers optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0659e7f9992d5a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:12.623759Z",
     "start_time": "2024-01-31T04:15:12.448254Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 17:19:17.533318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 17:19:17.652230: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "2024-02-13 17:19:17.652323: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "2024-02-13 17:19:17.652511: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-13 17:19:17.706912: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import io\n",
    "import numpy as np\n",
    "import os\n",
    "import ast\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer, BertConfig, TrainingArguments, Trainer, TextClassificationPipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from sklearn.utils import class_weight\n",
    "import optuna\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, CategoricalParameter\n",
    "from sagemaker.tuner import HyperparameterTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171338a004d78e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:14.156818Z",
     "start_time": "2024-01-31T04:15:14.021969Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name='us-west-2'\n",
    "bucket_name = 'aai-540-final-data'\n",
    "\n",
    "session = sagemaker.Session()\n",
    "featurestore_runtime = session.boto_session.client(service_name='sagemaker-featurestore-runtime', region_name=region_name)\n",
    "feature_group_name = 'emotion_feature_group_13_03_13_24_1707794028'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b17072a1-30d4-4fa4-b0f0-e10ed790b424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "athena_client = boto3.client('athena', region_name=region_name)\n",
    "query_string = f\"\"\"\n",
    "SELECT * FROM \"{feature_group_name}\"\n",
    "WHERE data_type = 'train'\n",
    "\"\"\"\n",
    "output_location = f's3://{bucket_name}/athena/results/'\n",
    "\n",
    "response_train = athena_client.start_query_execution(\n",
    "    QueryString=query_string,\n",
    "    QueryExecutionContext={\n",
    "        'Database': 'sagemaker_featurestore'\n",
    "    },\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': output_location,\n",
    "    }\n",
    ")\n",
    "train_location_id = response_train['QueryExecutionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4a22a5-27c1-4f19-8747-710d08027ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_query_string = f\"\"\"\n",
    "SELECT * FROM \"{feature_group_name}\"\n",
    "WHERE data_type = 'val'\n",
    "\"\"\"\n",
    "\n",
    "response_val = athena_client.start_query_execution(\n",
    "    QueryString=val_query_string,\n",
    "    QueryExecutionContext={\n",
    "        'Database': 'sagemaker_featurestore'\n",
    "    },\n",
    "    ResultConfiguration={\n",
    "        'OutputLocation': output_location,\n",
    "    }\n",
    ")\n",
    "val_location_id = response_val['QueryExecutionId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f221fb-fa7c-45a2-870a-226e0641e7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = session.boto_session.client('s3')\n",
    "s3_path = 'athena/results/'\n",
    "s3_train_location = s3_path + train_location_id + '.csv'\n",
    "s3_val_location = s3_path + val_location_id + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d322ace08721011a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:16.586646Z",
     "start_time": "2024-01-31T04:15:15.805471Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_obj = s3.get_object(Bucket=bucket_name, Key=s3_train_location)\n",
    "val_data_obj = s3.get_object(Bucket=bucket_name, Key=s3_val_location)\n",
    "\n",
    "df_train = pd.read_csv(io.BytesIO(train_data_obj['Body'].read()))\n",
    "df_val = pd.read_csv(io.BytesIO(val_data_obj['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c327182-05a0-4a19-b71a-dcfef59fa8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>emotions</th>\n",
       "      <th>text</th>\n",
       "      <th>eventtime</th>\n",
       "      <th>id</th>\n",
       "      <th>data_type</th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 4067, 2017, 1010, 2008, 2515, 4025, 2000...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>Thank You, that does seem to be the consensus.</td>\n",
       "      <td>1.707794e+09</td>\n",
       "      <td>eemui59</td>\n",
       "      <td>train</td>\n",
       "      <td>2024-02-13 03:20:23.818</td>\n",
       "      <td>2024-02-13 03:14:47.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2471, 2066, 1031, 2171, 1033, 3226, 2003...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Almost like [NAME] culture is written to be of...</td>\n",
       "      <td>1.707794e+09</td>\n",
       "      <td>eejenva</td>\n",
       "      <td>train</td>\n",
       "      <td>2024-02-13 03:20:23.818</td>\n",
       "      <td>2024-02-13 03:14:47.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2821, 2057, 1005, 2128, 2725, 2023, 2153...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>Oh we're doing this again huh</td>\n",
       "      <td>1.707794e+09</td>\n",
       "      <td>ed4i059</td>\n",
       "      <td>train</td>\n",
       "      <td>2024-02-13 03:20:23.818</td>\n",
       "      <td>2024-02-13 03:14:48.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 11867, 23644, 1010, 2008, 2001, 2919, 12...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Sphh, that was badass. I say that went well.</td>\n",
       "      <td>1.707794e+09</td>\n",
       "      <td>eelexo7</td>\n",
       "      <td>train</td>\n",
       "      <td>2024-02-13 03:20:23.818</td>\n",
       "      <td>2024-02-13 03:14:48.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 1045, 2293, 2043, 4268, 2131, 24995, 199...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>affectionate</td>\n",
       "      <td>I love when kids get cocky and then fall / get...</td>\n",
       "      <td>1.707794e+09</td>\n",
       "      <td>eekzamr</td>\n",
       "      <td>train</td>\n",
       "      <td>2024-02-13 03:20:23.818</td>\n",
       "      <td>2024-02-13 03:14:48.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 4067, 2017, 1010, 2008, 2515, 4025, 2000...   \n",
       "1  [101, 2471, 2066, 1031, 2171, 1033, 3226, 2003...   \n",
       "2  [101, 2821, 2057, 1005, 2128, 2725, 2023, 2153...   \n",
       "3  [101, 11867, 23644, 1010, 2008, 2001, 2919, 12...   \n",
       "4  [101, 1045, 2293, 2043, 4268, 2131, 24995, 199...   \n",
       "\n",
       "                                      attention_mask      emotions  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...         happy   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...         anger   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...         anger   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...       neutral   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  affectionate   \n",
       "\n",
       "                                                text     eventtime       id  \\\n",
       "0    Thank You, that does seem to be the consensus.   1.707794e+09  eemui59   \n",
       "1  Almost like [NAME] culture is written to be of...  1.707794e+09  eejenva   \n",
       "2                      Oh we're doing this again huh  1.707794e+09  ed4i059   \n",
       "3       Sphh, that was badass. I say that went well.  1.707794e+09  eelexo7   \n",
       "4  I love when kids get cocky and then fall / get...  1.707794e+09  eekzamr   \n",
       "\n",
       "  data_type               write_time      api_invocation_time  is_deleted  \n",
       "0     train  2024-02-13 03:20:23.818  2024-02-13 03:14:47.000       False  \n",
       "1     train  2024-02-13 03:20:23.818  2024-02-13 03:14:47.000       False  \n",
       "2     train  2024-02-13 03:20:23.818  2024-02-13 03:14:48.000       False  \n",
       "3     train  2024-02-13 03:20:23.818  2024-02-13 03:14:48.000       False  \n",
       "4     train  2024-02-13 03:20:23.818  2024-02-13 03:14:48.000       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d49798e821d0fe11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:17:47.078763Z",
     "start_time": "2024-01-31T04:17:47.060213Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_categories = {\n",
    "\t\"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "\t\"disgust\": [\"disgust\"],\n",
    "\t\"fear\": [\"fear\", \"nervousness\"],\n",
    "\t\"happy\": [\"joy\", \"amusement\", \"approval\", \"gratitude\"],\n",
    "\t\"optimistic\": [\"optimism\", \"relief\", \"pride\", \"excitement\"],\n",
    "\t\"affectionate\": [ \"love\", \"caring\", \"admiration\",  \"desire\"],\n",
    "\t\"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "\t\"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"],\n",
    "\t\"neutral\": [\"neutral\"]\n",
    "}\n",
    "category_to_index = {category: index for index, category in enumerate(emotion_categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00016a64-9536-4460-9097-2eb098661905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_store_to_dataset(dataframe, category_to_index, shuffle=True, batch_size=16):\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    # Extract labels and convert to numerical values\n",
    "    labels = dataframe.pop('emotions').apply(lambda x: category_to_index[x]).values\n",
    "    \n",
    "    # Parse 'input_ids' and 'attention_mask' from strings to lists of integers\n",
    "    input_ids = dataframe['input_ids'].apply(ast.literal_eval).tolist()\n",
    "    attention_mask = dataframe['attention_mask'].apply(ast.literal_eval).tolist()\n",
    "    \n",
    "    # Convert lists to TensorFlow tensors\n",
    "    input_ids = tf.constant(input_ids, dtype=tf.int32)\n",
    "    attention_mask = tf.constant(attention_mask, dtype=tf.int32)\n",
    "    \n",
    "    # Create a TensorFlow dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices(({\n",
    "        \"input_ids\": input_ids, \n",
    "        \"attention_mask\": attention_mask\n",
    "    }, labels))\n",
    "    \n",
    "    # Shuffle and batch the dataset\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7815fefe3d330ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:20.579353Z",
     "start_time": "2024-01-31T04:15:20.564930Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 17:20:36.752821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:36.762279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:36.764106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:36.766319: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 17:20:36.766690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:36.768505: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:36.770276: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:37.694405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:37.696128: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:37.697617: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-02-13 17:20:37.699059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13653 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_dataset = feature_store_to_dataset(df_train, category_to_index, shuffle=True, batch_size=batch_size)\n",
    "val_dataset = feature_store_to_dataset(df_val, category_to_index, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f61ffc2221f3e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:35.426777Z",
     "start_time": "2024-01-31T04:15:32.691323Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5459b86-84ee-48cd-9d50-a2c41bc21010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "decay_steps = num_epochs * (len(df_train) / batch_size)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=5e-5,\n",
    "    decay_steps=decay_steps,\n",
    "    power=1.0)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cacaebb3bd73371f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T04:26:18.222192Z",
     "start_time": "2024-01-31T04:21:58.322646Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2671/2671 [==============================] - 456s 165ms/step - loss: 1.1751 - accuracy: 0.5920 - val_loss: 1.0989 - val_accuracy: 0.6190\n",
      "Epoch 2/4\n",
      "2671/2671 [==============================] - 439s 164ms/step - loss: 0.9568 - accuracy: 0.6632 - val_loss: 1.1081 - val_accuracy: 0.6093\n",
      "Epoch 3/4\n",
      "2671/2671 [==============================] - 439s 164ms/step - loss: 0.7961 - accuracy: 0.7226 - val_loss: 1.1788 - val_accuracy: 0.5823\n",
      "Epoch 4/4\n",
      "2671/2671 [==============================] - 439s 164ms/step - loss: 0.6642 - accuracy: 0.7686 - val_loss: 1.2289 - val_accuracy: 0.6002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8ec14c190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model with validation data\n",
    "model.fit(train_dataset, \n",
    "          epochs=num_epochs, \n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2258063-f602-48fd-b2ab-2e344a4a58f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.004577369429171085},\n",
       "  {'label': 'LABEL_1', 'score': 0.032892897725105286},\n",
       "  {'label': 'LABEL_2', 'score': 0.9122949838638306},\n",
       "  {'label': 'LABEL_3', 'score': 0.004681961145251989},\n",
       "  {'label': 'LABEL_4', 'score': 0.0033336216583848},\n",
       "  {'label': 'LABEL_5', 'score': 0.0009535696008242667},\n",
       "  {'label': 'LABEL_6', 'score': 0.013790403492748737},\n",
       "  {'label': 'LABEL_7', 'score': 0.004066551569849253},\n",
       "  {'label': 'LABEL_8', 'score': 0.023408683016896248}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)\n",
    "\n",
    "pipe(\"There is terrible news today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b0f7c14-eaf5-48f4-9729-4e68a0481f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0d62726-fe2f-4421-a338-f9cabd3fb205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/tokenizer_config.json',\n",
       " 'models/special_tokens_map.json',\n",
       " 'models/vocab.txt',\n",
       " 'models/added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "026263e3-19f0-48d9-b576-aee02d604087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./tokenizer_config.json\n",
      "./.ipynb_checkpoints/\n",
      "./config.json\n",
      "./special_tokens_map.json\n",
      "./vocab.txt\n",
      "./tf_model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_file = 'base_model.tar.gz'\n",
    "\n",
    "command = f\"tar -czvf {tar_file} -C {model_dir} .\"\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edf1b6b7-4e88-4d39-bb26-d585649c3370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_tar_file_path = tar_file\n",
    "s3_key = f'models/{tar_file}'\n",
    "s3.upload_file(local_tar_file_path, bucket_name, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b1071-dd91-4757-8521-a61d6d8df1fb",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81c3a94f-01a4-4ec2-8466-3050337c280c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIN_EPOCHS = 3\n",
    "MAX_EPOCHS = 5\n",
    "LR_MIN = 5e-6\n",
    "LR_CEIL = 5e-5\n",
    "LR_SCHEDULERS = [\"PolynomialDecay\", \"CosineDecay\"]\n",
    "BATCH_SIZE_MIN = 8\n",
    "BATCH_SIZE_CEIL = 16\n",
    "NUM_LAYERS_FREEZE_MIN = 0\n",
    "NUM_LAYERS_FREEZE_CEIL = 6\n",
    "DROP_OUT_PROP_MIN = 0.2\n",
    "DROP_OUT_PROP_CEIL = 0.4\n",
    "DECAY_STEPS_MIN = 5000\n",
    "DECAY_STEPS_CEIL = 8000\n",
    "POWER_EXP_MIN = 1.0\n",
    "POWER_EXP_CEIL = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e13fa4-7166-4732-8b1f-14cdcaa676d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):     \n",
    "    num_layers_to_freeze = trial.suggest_int(\"num_layers_to_freeze\", NUM_LAYERS_FREEZE_MIN, NUM_LAYERS_FREEZE_CEIL)\n",
    "    dropout_prob = trial.suggest_float(\"dropout_prob\", DROP_OUT_PROP_MIN, DROP_OUT_PROP_CEIL)\n",
    "    config = BertConfig.from_pretrained('bert-base-uncased', num_labels=9, hidden_dropout_prob=dropout_prob, attention_probs_dropout_prob=dropout_prob)\n",
    "    \n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', config=config)\n",
    "    for layer in model.bert.encoder.layer[:num_layers_to_freeze]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    lr_scheduler_name = trial.suggest_categorical(\"lr_scheduler\", LR_SCHEDULERS)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", BATCH_SIZE_MIN, BATCH_SIZE_CEIL)\n",
    "    \n",
    "    decay_steps = 0\n",
    "    if lr_scheduler_name == \"PolynomialDecay\":\n",
    "        initial_learning_rate = trial.suggest_float(\"initial_learning_rate_poly\", LR_MIN, LR_CEIL)\n",
    "        decay_steps = trial.suggest_int(\"decay_steps_poly\", DECAY_STEPS_MIN, DECAY_STEPS_CEIL)\n",
    "        power = trial.suggest_float(\"power_poly\", POWER_EXP_MIN, POWER_EXP_CEIL)\n",
    "        lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        power=power)\n",
    "    elif lr_scheduler_name == \"CosineDecay\":\n",
    "        initial_learning_rate = trial.suggest_float(\"initial_learning_rate_cosine\", LR_MIN, LR_CEIL)\n",
    "        decay_steps = trial.suggest_int(\"decay_steps_cosine\", DECAY_STEPS_MIN, DECAY_STEPS_CEIL)\n",
    "        lr_schedule = tf.keras.experimental.CosineDecay(\n",
    "            initial_learning_rate=initial_learning_rate,\n",
    "            decay_steps=decay_steps,\n",
    "            alpha=0.0)\n",
    "        \n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", MIN_EPOCHS, MAX_EPOCHS)\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "    print(f\"lr_scheduler: {lr_scheduler_name}, batch_size: {batch_size}, dropout: {dropout_prob}, num_frozen: {num_layers_to_freeze}, initial_learning_rate: {initial_learning_rate}, decay_steps: {decay_steps}, num_epochs: {num_epochs}\")\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    trainer = model.fit(train_dataset, \n",
    "              epochs=num_epochs, \n",
    "              validation_data=val_dataset)\n",
    "    result = trainer.history\n",
    "    \n",
    "    return result['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0393f2-d104-4a8f-8493-0580dbad0cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 18:59:27,050] A new study created in memory with name: no-name-058c75ed-dfbd-4583-90b2-a10d1d47db74\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d035e7-aabb-4870-b380-e944bcb95d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_scheduler: CosineDecay, batch_size: 14, dropout: 0.2437810201978664, num_frozen: 6, initial_learning_rate: 2.1005659482580446e-05, decay_steps: 6308, num_epochs: 3\n",
      "Epoch 1/3\n",
      "2671/2671 [==============================] - 409s 148ms/step - loss: 1.2621 - accuracy: 0.5616 - val_loss: 1.1344 - val_accuracy: 0.6057\n",
      "Epoch 2/3\n",
      "2671/2671 [==============================] - 394s 147ms/step - loss: 1.0456 - accuracy: 0.6332 - val_loss: 1.1132 - val_accuracy: 0.6088\n",
      "Epoch 3/3\n",
      "2671/2671 [==============================] - 396s 148ms/step - loss: 0.9978 - accuracy: 0.6490 - val_loss: 1.1135 - val_accuracy: 0.6074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 19:19:27,926] Trial 0 finished with value: 1.1135334968566895 and parameters: {'num_layers_to_freeze': 6, 'dropout_prob': 0.2437810201978664, 'lr_scheduler': 'CosineDecay', 'batch_size': 14, 'initial_learning_rate_cosine': 2.1005659482580446e-05, 'decay_steps_cosine': 6308, 'num_epochs': 3}. Best is trial 0 with value: 1.1135334968566895.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_scheduler: CosineDecay, batch_size: 12, dropout: 0.359094842080101, num_frozen: 0, initial_learning_rate: 4.823502706062804e-05, decay_steps: 7735, num_epochs: 3\n",
      "Epoch 1/3\n",
      "2671/2671 [==============================] - 471s 170ms/step - loss: 1.3128 - accuracy: 0.5487 - val_loss: 1.1705 - val_accuracy: 0.5900\n",
      "Epoch 2/3\n",
      "2671/2671 [==============================] - 449s 168ms/step - loss: 1.0624 - accuracy: 0.6269 - val_loss: 1.1630 - val_accuracy: 0.5915\n",
      "Epoch 3/3\n",
      "2671/2671 [==============================] - 447s 167ms/step - loss: 0.9630 - accuracy: 0.6612 - val_loss: 1.1634 - val_accuracy: 0.5941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-13 19:42:15,859] Trial 1 finished with value: 1.1633527278900146 and parameters: {'num_layers_to_freeze': 0, 'dropout_prob': 0.359094842080101, 'lr_scheduler': 'CosineDecay', 'batch_size': 12, 'initial_learning_rate_cosine': 4.823502706062804e-05, 'decay_steps_cosine': 7735, 'num_epochs': 3}. Best is trial 0 with value: 1.1135334968566895.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_scheduler: CosineDecay, batch_size: 16, dropout: 0.3253139877174047, num_frozen: 4, initial_learning_rate: 1.0311930946365403e-05, decay_steps: 5829, num_epochs: 5\n",
      "Epoch 1/5\n",
      "2671/2671 [==============================] - 427s 154ms/step - loss: 1.4198 - accuracy: 0.5051 - val_loss: 1.2324 - val_accuracy: 0.5708\n",
      "Epoch 2/5\n",
      "2671/2671 [==============================] - 409s 153ms/step - loss: 1.1749 - accuracy: 0.5961 - val_loss: 1.1950 - val_accuracy: 0.5864\n",
      "Epoch 3/5\n",
      "2671/2671 [==============================] - 410s 154ms/step - loss: 1.1500 - accuracy: 0.6047 - val_loss: 1.1953 - val_accuracy: 0.5866\n",
      "Epoch 4/5\n",
      "2671/2671 [==============================] - 410s 153ms/step - loss: 1.1513 - accuracy: 0.6038 - val_loss: 1.1953 - val_accuracy: 0.5866\n",
      "Epoch 5/5\n",
      " 851/2671 [========>.....................] - ETA: 4:25 - loss: 1.1320 - accuracy: 0.6165"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a1091-7bd9-47f7-94e1-90896e33e4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.11.0 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.11.0-gpu-py39-cu112-ubuntu20.04-sagemaker-v1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
