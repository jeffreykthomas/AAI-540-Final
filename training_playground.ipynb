{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:12.623759Z",
     "start_time": "2024-01-31T04:15:12.448254Z"
    }
   },
   "id": "f0659e7f9992d5a6",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aws_access_key_id='ASIAX4UI5AMFD22KJHPV'\n",
    "aws_secret_access_key='LkZ4VXrr+b2nGODWLGDOfJXPX6QiAKlE1jeu5Ek8'\n",
    "aws_session_token='FwoGZXIvYXdzEGsaDLffLvGSwjx++b+FlyK/AWPmMaKnw++HFouiUqaVXYUcQeYrUXA74K4Q5iunH86vh+XrQI31bmPEDCJpjcWngvEGiE9a4CE9sxjwDt+c9+l6fsdI1y4jpHWiTHNLJ3KEAE7XFV34h9t/RDTrZwcf0vd5r23ACA32pvZak0IGbpAoDSTDpCn9GUZ3WT48pkPrjsIVCZXgf8KLmw00QNZdEGExWsOtlAw/+22iAKi4rS6dXkq2+7sOB32AX/6/Kz4JhNMxiSFz2ktSz8H+jkA2KNHM5q0GMi2jBcwfle7bGkcSu+IyaL6eUxHaPg5pePbBtMcGvDrA0Tukc4mFhHKA0tgL+Vk='\n",
    "region_name='us-west-2'\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=aws_access_key_id,\n",
    "                        aws_secret_access_key=aws_secret_access_key,\n",
    "                        aws_session_token=aws_session_token,\n",
    "                        region_name=region_name)\n",
    "\n",
    "s3 = session.client('s3')\n",
    "bucket_name = 'aai-540-final-data'\n",
    "s3_path = 'data/pre_processed_data.tsv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:14.156818Z",
     "start_time": "2024-01-31T04:15:14.021969Z"
    }
   },
   "id": "171338a004d78e2d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://aai-540-final-data.s3.amazonaws.com/data/pre_processed_data.tsv?AWSAccessKeyId=ASIAX4UI5AMFD22KJHPV&Signature=dUP6TZHxL9mkL%2FhTSbS5jSgawWs%3D&x-amz-security-token=FwoGZXIvYXdzEGsaDLffLvGSwjx%2B%2Bb%2BFlyK%2FAWPmMaKnw%2B%2BHFouiUqaVXYUcQeYrUXA74K4Q5iunH86vh%2BXrQI31bmPEDCJpjcWngvEGiE9a4CE9sxjwDt%2Bc9%2Bl6fsdI1y4jpHWiTHNLJ3KEAE7XFV34h9t%2FRDTrZwcf0vd5r23ACA32pvZak0IGbpAoDSTDpCn9GUZ3WT48pkPrjsIVCZXgf8KLmw00QNZdEGExWsOtlAw%2F%2B22iAKi4rS6dXkq2%2B7sOB32AX%2F6%2FKz4JhNMxiSFz2ktSz8H%2BjkA2KNHM5q0GMi2jBcwfle7bGkcSu%2BIyaL6eUxHaPg5pePbBtMcGvDrA0Tukc4mFhHKA0tgL%2BVk%3D&Expires=1706678115\n",
      "                                                text  emotions       id\n",
      "0                     Shhh don't give them the idea!         2  eebl3z7\n",
      "1                                    Is this real? ðŸ¤”         7  edjldcm\n",
      "2  My favorite pod when they are fresh & clear. S...         9  ee7j34k\n",
      "3  Forgot what it's like to actually not dislike ...        27  edoz8qt\n",
      "4  Iâ€™m more worried about the dude getting pissed...        19  edo8t8y\n"
     ]
    }
   ],
   "source": [
    "# Generate the URL to get 'key-name' from 'bucket-name'\n",
    "url = s3.generate_presigned_url(\n",
    "    ClientMethod='get_object',\n",
    "    Params={\n",
    "        'Bucket': bucket_name,\n",
    "        'Key': s3_path\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the URL for debugging\n",
    "print(url)\n",
    "\n",
    "# Use pandas to load the csv file\n",
    "try:\n",
    "    df = pd.read_csv(url, sep='\\t')\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:16.586646Z",
     "start_time": "2024-01-31T04:15:15.805471Z"
    }
   },
   "id": "d322ace08721011a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# split into train, text, val\n",
    "X = df.drop('emotions', axis=1)\n",
    "y = df['emotions']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Further split the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:17:47.078763Z",
     "start_time": "2024-01-31T04:17:47.060213Z"
    }
   },
   "id": "d49798e821d0fe11",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12418    27\n22289    27\n20074     1\n33910    17\n25163    20\n         ..\n51824    27\n16566    27\n40366    27\n13497    27\n39242     8\nName: emotions, Length: 42731, dtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:20.579353Z",
     "start_time": "2024-01-31T04:15:20.564930Z"
    }
   },
   "id": "a7815fefe3d330ce",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "anger            5276\ndisgust           577\nfear              619\nhappy            7919\noptimistic       1748\naffectionate     7007\nsadness          2591\nsurprise         4363\nneutral         12631\ndtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the file with emotion label names\n",
    "emotion_labels_obj = s3.get_object(Bucket=bucket_name, Key='data/emotions.txt')\n",
    "emotion_labels_data = emotion_labels_obj['Body'].read()\n",
    "\n",
    "# Converting the data from bytes to string and splitting by lines\n",
    "emotion_labels = emotion_labels_data.decode('utf-8').splitlines()\n",
    "# Split emotions column to get count of each emotion individually\n",
    "split_emotions = y_train.astype(str).str.split(',')\n",
    "all_emotions = split_emotions.explode().astype(int)\n",
    "# Creating a mapping of indices to emotion labels\n",
    "emotion_index_to_label = {index: label for index, label in enumerate(emotion_labels)}\n",
    "\n",
    "# Applying the mapping to the emotions dataset\n",
    "labeled_emotions = all_emotions.map(emotion_index_to_label)\n",
    "\n",
    "# Counting occurrences of each emotion label\n",
    "labeled_emotion_counts = labeled_emotions.value_counts()\n",
    "\n",
    "emotion_categories = {\n",
    "\t\"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "\t\"disgust\": [\"disgust\"],\n",
    "\t\"fear\": [\"fear\", \"nervousness\"],\n",
    "\t\"happy\": [\"joy\", \"amusement\", \"approval\", \"gratitude\"],\n",
    "\t\"optimistic\": [\"optimism\", \"relief\", \"pride\", \"excitement\"],\n",
    "\t\"affectionate\": [ \"love\", \"caring\", \"admiration\",  \"desire\"],\n",
    "\t\"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\",  \"remorse\"],\n",
    "\t\"surprise\": [\"surprise\", \"realization\", \"confusion\", \"curiosity\"],\n",
    "\t\"neutral\": [\"neutral\"]\n",
    "} \n",
    "\n",
    "emotion_to_category = {}\n",
    "for category, emotions in emotion_categories.items():\n",
    "\tfor emotion in emotions:\n",
    "\t\temotion_to_category[emotion] = category\n",
    "\n",
    "category_counts = pd.Series(dtype=int).reindex(emotion_categories.keys(), fill_value=0)\n",
    "\n",
    "for emotion, count in labeled_emotion_counts.items():\n",
    "\tcategory = emotion_to_category[emotion]\n",
    "\tif category:\n",
    "\t\tcategory_counts[category] += count\n",
    "\n",
    "category_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:23.459812Z",
     "start_time": "2024-01-31T04:15:23.044851Z"
    }
   },
   "id": "effda0d96e49bec6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define the base BERT model from Hugging Face\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "from tensorflow.data import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:16:58.647508Z",
     "start_time": "2024-01-31T04:16:58.639713Z"
    }
   },
   "id": "ecb97a1f10cbe45a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of labels\n",
    "num_labels = len(category_counts)\n",
    "num_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:29.417829Z",
     "start_time": "2024-01-31T04:15:29.415132Z"
    }
   },
   "id": "6b4244944fc5efcb",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 20:15:32.993519: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-01-30 20:15:32.993541: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 96.00 GB\n",
      "2024-01-30 20:15:32.993546: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 36.00 GB\n",
      "2024-01-30 20:15:32.993596: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-30 20:15:32.993635: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:15:35.426777Z",
     "start_time": "2024-01-31T04:15:32.691323Z"
    }
   },
   "id": "9f61ffc2221f3e95",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert the labels given the emotion_categories mapping given int is not iterable\n",
    "# Convert the labels given the emotion_categories mapping\n",
    "y_train = y_train.apply(lambda x: emotion_to_category[emotion_index_to_label[x]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:03.255477Z",
     "start_time": "2024-01-31T04:21:03.247941Z"
    }
   },
   "id": "edc0c26430c0edd4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_val = y_val.apply(lambda x: emotion_to_category[emotion_index_to_label[x]])\n",
    "y_test = y_test.apply(lambda x: emotion_to_category[emotion_index_to_label[x]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:04.818038Z",
     "start_time": "2024-01-31T04:21:04.816267Z"
    }
   },
   "id": "9da194b7d16e9e49",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "emotions\nneutral         12631\nhappy            7919\naffectionate     7007\nanger            5276\nsurprise         4363\nsadness          2591\noptimistic       1748\nfear              619\ndisgust           577\nName: count, dtype: int64"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:06.354670Z",
     "start_time": "2024-01-31T04:21:06.350038Z"
    }
   },
   "id": "1b97c269a962c889",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Tokenize the input data\n",
    "train_encodings = tokenizer(X_train['text'].tolist(), truncation=True, padding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:18:15.021918Z",
     "start_time": "2024-01-31T04:18:10.197151Z"
    }
   },
   "id": "7cd7c0056c45119c",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "12418         neutral\n22289         neutral\n20074           happy\n33910           happy\n25163      optimistic\n             ...     \n51824         neutral\n16566         neutral\n40366         neutral\n13497         neutral\n39242    affectionate\nName: emotions, Length: 42731, dtype: object"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:11.142361Z",
     "start_time": "2024-01-31T04:21:11.133465Z"
    }
   },
   "id": "fa5e563960febde3",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'anger': 0,\n 'disgust': 1,\n 'fear': 2,\n 'happy': 3,\n 'optimistic': 4,\n 'affectionate': 5,\n 'sadness': 6,\n 'surprise': 7,\n 'neutral': 8}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_to_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:20:38.554872Z",
     "start_time": "2024-01-31T04:20:38.551760Z"
    }
   },
   "id": "7031d726608e6d29",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a dictionary that maps each category to its index\n",
    "category_to_index = {category: index for index, category in enumerate(emotion_categories)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:17.166605Z",
     "start_time": "2024-01-31T04:21:17.163296Z"
    }
   },
   "id": "d853065f92cfb211",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Convert the categories in y_train to indices\n",
    "y_train_num = y_train.apply(lambda x: category_to_index[x])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:18.595671Z",
     "start_time": "2024-01-31T04:21:18.594220Z"
    }
   },
   "id": "5e75e8d532f3c864",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_tensor_slices((\n",
    "\tdict(train_encodings),\n",
    "\ty_train_num.values\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:21:48.045184Z",
     "start_time": "2024-01-31T04:21:26.654781Z"
    }
   },
   "id": "ceae5a0129118dee",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 20:22:03.798162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 272/2671 [==>...........................] - ETA: 32:22 - loss: 2.4059 - accuracy: 0.1491"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:249\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m InterpolateRuntimeError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    243\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcontrol_dependencies(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_options\u001B[38;5;241m.\u001B[39mcontrol_captures):\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;66;03m# The caller must use record_operation to record this operation in the\u001B[39;00m\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;66;03m# eager case, so we enforce the same requirement for the non-eager\u001B[39;00m\n\u001B[1;32m    246\u001B[0m     \u001B[38;5;66;03m# case by explicitly pausing recording. We don't have a gradient\u001B[39;00m\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;66;03m# registered for PartitionedCall, so recording this operation confuses\u001B[39;00m\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;66;03m# forwardprop code (GradientTape manages to ignore it).\u001B[39;00m\n\u001B[0;32m--> 249\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrecord\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop_recording\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecuting_eagerly\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:144\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[0;34m(self, typ, value, traceback)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 144\u001B[0m         \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgen)\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/AAI-540-Final/myvenv/lib/python3.11/site-packages/tensorflow/python/eager/record.py:64\u001B[0m, in \u001B[0;36mstop_recording\u001B[0;34m()\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_stopped:\n\u001B[0;32m---> 64\u001B[0m     \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_TapeSetRestartOnThread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T04:26:18.222192Z",
     "start_time": "2024-01-31T04:21:58.322646Z"
    }
   },
   "id": "cacaebb3bd73371f",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b0e3b4e8c22f6b4b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
